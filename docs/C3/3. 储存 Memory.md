# ç¬¬ä¸‰ç«  å‚¨å­˜

åœ¨ä¸è¯­è¨€æ¨¡å‹äº¤äº’æ—¶ï¼Œä½ å¯èƒ½å·²ç»æ³¨æ„åˆ°ä¸€ä¸ªå…³é”®é—®é¢˜ï¼šå®ƒä»¬å¹¶ä¸è®°å¿†ä½ ä¹‹å‰çš„äº¤æµå†…å®¹ï¼Œè¿™åœ¨æˆ‘ä»¬æ„å»ºä¸€äº›åº”ç”¨ç¨‹åºï¼ˆå¦‚èŠå¤©æœºå™¨äººï¼‰çš„æ—¶å€™ï¼Œå¸¦æ¥äº†å¾ˆå¤§çš„æŒ‘æˆ˜ï¼Œä½¿å¾—å¯¹è¯ä¼¼ä¹ç¼ºä¹çœŸæ­£çš„è¿ç»­æ€§ã€‚å› æ­¤ï¼Œåœ¨æœ¬èŠ‚ä¸­æˆ‘ä»¬å°†ä»‹ç» LangChain ä¸­çš„å‚¨å­˜æ¨¡å—ï¼Œå³å¦‚ä½•å°†å…ˆå‰çš„å¯¹è¯åµŒå…¥åˆ°è¯­è¨€æ¨¡å‹ä¸­çš„ï¼Œä½¿å…¶å…·æœ‰è¿ç»­å¯¹è¯çš„èƒ½åŠ›ã€‚

å½“ä½¿ç”¨ LangChain ä¸­çš„å‚¨å­˜(Memory)æ¨¡å—æ—¶ï¼Œå®ƒæ—¨åœ¨ä¿å­˜ã€ç»„ç»‡å’Œè·Ÿè¸ªæ•´ä¸ªå¯¹è¯çš„å†å²ï¼Œä»è€Œä¸ºç”¨æˆ·å’Œæ¨¡å‹ä¹‹é—´çš„äº¤äº’æä¾›è¿ç»­çš„ä¸Šä¸‹æ–‡ã€‚

LangChain æä¾›äº†å¤šç§å‚¨å­˜ç±»å‹ã€‚å…¶ä¸­ï¼Œç¼“å†²åŒºå‚¨å­˜å…è®¸ä¿ç•™æœ€è¿‘çš„èŠå¤©æ¶ˆæ¯ï¼Œæ‘˜è¦å‚¨å­˜åˆ™æä¾›äº†å¯¹æ•´ä¸ªå¯¹è¯çš„æ‘˜è¦ã€‚å®ä½“å‚¨å­˜åˆ™å…è®¸åœ¨å¤šè½®å¯¹è¯ä¸­ä¿ç•™æœ‰å…³ç‰¹å®šå®ä½“çš„ä¿¡æ¯ã€‚è¿™äº›è®°å¿†ç»„ä»¶éƒ½æ˜¯æ¨¡å—åŒ–çš„ï¼Œå¯ä¸å…¶ä»–ç»„ä»¶ç»„åˆä½¿ç”¨ï¼Œä»è€Œå¢å¼ºæœºå™¨äººçš„å¯¹è¯ç®¡ç†èƒ½åŠ›ã€‚å‚¨å­˜æ¨¡å—å¯ä»¥é€šè¿‡ç®€å•çš„ API è°ƒç”¨æ¥è®¿é—®å’Œæ›´æ–°ï¼Œå…è®¸å¼€å‘äººå‘˜æ›´è½»æ¾åœ°å®ç°å¯¹è¯å†å²è®°å½•çš„ç®¡ç†å’Œç»´æŠ¤ã€‚

æ­¤æ¬¡è¯¾ç¨‹ä¸»è¦ä»‹ç»å…¶ä¸­å››ç§å‚¨å­˜æ¨¡å—ï¼Œå…¶ä»–æ¨¡å—å¯æŸ¥çœ‹æ–‡æ¡£å­¦ä¹ ã€‚
- å¯¹è¯ç¼“å­˜å‚¨å­˜ (ConversationBufferMemoryï¼‰
- å¯¹è¯ç¼“å­˜çª—å£å‚¨å­˜ (ConversationBufferWindowMemoryï¼‰
- å¯¹è¯ä»¤ç‰Œç¼“å­˜å‚¨å­˜ (ConversationTokenBufferMemoryï¼‰
- å¯¹è¯æ‘˜è¦ç¼“å­˜å‚¨å­˜ (ConversationSummaryBufferMemoryï¼‰

åœ¨ LangChain ä¸­ï¼Œå‚¨å­˜æŒ‡çš„æ˜¯å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰çš„çŸ­æœŸè®°å¿†ã€‚ä¸ºä»€ä¹ˆæ˜¯çŸ­æœŸè®°å¿†ï¼Ÿé‚£æ˜¯å› ä¸ºLLMè®­ç»ƒå¥½ä¹‹å (è·å¾—äº†ä¸€äº›é•¿æœŸè®°å¿†)ï¼Œå®ƒçš„å‚æ•°ä¾¿ä¸ä¼šå› ä¸ºç”¨æˆ·çš„è¾“å…¥è€Œå‘ç”Ÿæ”¹å˜ã€‚å½“ç”¨æˆ·ä¸è®­ç»ƒå¥½çš„LLMè¿›è¡Œå¯¹è¯æ—¶ï¼ŒLLM ä¼šæš‚æ—¶è®°ä½ç”¨æˆ·çš„è¾“å…¥å’Œå®ƒå·²ç»ç”Ÿæˆçš„è¾“å‡ºï¼Œä»¥ä¾¿é¢„æµ‹ä¹‹åçš„è¾“å‡ºï¼Œè€Œæ¨¡å‹è¾“å‡ºå®Œæ¯•åï¼Œå®ƒä¾¿ä¼šâ€œé—å¿˜â€ä¹‹å‰ç”¨æˆ·çš„è¾“å…¥å’Œå®ƒçš„è¾“å‡ºã€‚å› æ­¤ï¼Œä¹‹å‰çš„è¿™äº›ä¿¡æ¯åªèƒ½ç§°ä½œä¸º LLM çš„çŸ­æœŸè®°å¿†ã€‚  
  
ä¸ºäº†å»¶é•¿ LLM çŸ­æœŸè®°å¿†çš„ä¿ç•™æ—¶é—´ï¼Œåˆ™éœ€è¦å€ŸåŠ©ä¸€äº›å¤–éƒ¨å‚¨å­˜æ–¹å¼æ¥è¿›è¡Œè®°å¿†ï¼Œä»¥ä¾¿åœ¨ç”¨æˆ·ä¸ LLM å¯¹è¯ä¸­ï¼ŒLLM èƒ½å¤Ÿå°½å¯èƒ½çš„çŸ¥é“ç”¨æˆ·ä¸å®ƒæ‰€è¿›è¡Œçš„å†å²å¯¹è¯ä¿¡æ¯ã€‚ 

## ä¸€ã€å¯¹è¯ç¼“å­˜å‚¨å­˜
  

### 1.1 åˆå§‹åŒ–å¯¹è¯æ¨¡å‹

è®©æˆ‘ä»¬å…ˆæ¥åˆå§‹åŒ–å¯¹è¯æ¨¡å‹ã€‚

```python
from langchain.chains import ConversationChain
from langchain.chat_models import ChatOpenAI
from langchain.memory import ConversationBufferMemory

# è¿™é‡Œæˆ‘ä»¬å°†å‚æ•°temperatureè®¾ç½®ä¸º0.0ï¼Œä»è€Œå‡å°‘ç”Ÿæˆç­”æ¡ˆçš„éšæœºæ€§ã€‚
# å¦‚æœä½ æƒ³è¦æ¯æ¬¡å¾—åˆ°ä¸ä¸€æ ·çš„æœ‰æ–°æ„çš„ç­”æ¡ˆï¼Œå¯ä»¥å°è¯•å¢å¤§è¯¥å‚æ•°ã€‚
llm = ChatOpenAI(temperature=0.0)  
memory = ConversationBufferMemory()


# æ–°å»ºä¸€ä¸ª ConversationChain Class å®ä¾‹
# verboseå‚æ•°è®¾ç½®ä¸ºTrueæ—¶ï¼Œç¨‹åºä¼šè¾“å‡ºæ›´è¯¦ç»†çš„ä¿¡æ¯ï¼Œä»¥æä¾›æ›´å¤šçš„è°ƒè¯•æˆ–è¿è¡Œæ—¶ä¿¡æ¯ã€‚
# ç›¸åï¼Œå½“å°†verboseå‚æ•°è®¾ç½®ä¸ºFalseæ—¶ï¼Œç¨‹åºä¼šä»¥æ›´ç®€æ´çš„æ–¹å¼è¿è¡Œï¼Œåªè¾“å‡ºå…³é”®çš„ä¿¡æ¯ã€‚
conversation = ConversationChain(llm=llm, memory = memory, verbose=True )
```

### 1.2 ç¬¬ä¸€è½®å¯¹è¯

å½“æˆ‘ä»¬è¿è¡Œé¢„æµ‹(predict)æ—¶ï¼Œç”Ÿæˆäº†ä¸€äº›æç¤ºï¼Œå¦‚ä¸‹æ‰€è§ï¼Œä»–è¯´â€œä»¥ä¸‹æ˜¯äººç±»å’Œ AI ä¹‹é—´å‹å¥½çš„å¯¹è¯ï¼ŒAI å¥è°ˆâ€œç­‰ç­‰ï¼Œè¿™å®é™…ä¸Šæ˜¯ LangChain ç”Ÿæˆçš„æç¤ºï¼Œä»¥ä½¿ç³»ç»Ÿè¿›è¡Œå¸Œæœ›å’Œå‹å¥½çš„å¯¹è¯ï¼Œå¹¶ä¸”å¿…é¡»ä¿å­˜å¯¹è¯ï¼Œå¹¶æç¤ºäº†å½“å‰å·²å®Œæˆçš„æ¨¡å‹é“¾ã€‚


```python
conversation.predict(input="ä½ å¥½, æˆ‘å«çš®çš®é²")
```

    
    
    [1m> Entering new  chain...[0m
    Prompt after formatting:
    [32;1m[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.
    
    Current conversation:
    
    Human: ä½ å¥½, æˆ‘å«çš®çš®é²
    AI:[0m
    
    [1m> Finished chain.[0m





    'ä½ å¥½ï¼Œçš®çš®é²ï¼å¾ˆé«˜å…´è®¤è¯†ä½ ã€‚æˆ‘æ˜¯ä¸€ä¸ªAIåŠ©æ‰‹ï¼Œå¯ä»¥å›ç­”ä½ çš„é—®é¢˜å’Œæä¾›å¸®åŠ©ã€‚æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®ä½ çš„å—ï¼Ÿ'



### 1.3 ç¬¬äºŒè½®å¯¹è¯

å½“æˆ‘ä»¬è¿›è¡Œç¬¬äºŒè½®å¯¹è¯æ—¶ï¼Œå®ƒä¼šä¿ç•™ä¸Šé¢çš„æç¤º


```python
conversation.predict(input="1+1ç­‰äºå¤šå°‘ï¼Ÿ")
```

    
    
    [1m> Entering new ConversationChain chain...[0m
    Prompt after formatting:
    [32;1m[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.
    
    Current conversation:
    Human: ä½ å¥½, æˆ‘å«çš®çš®é²
    AI: ä½ å¥½ï¼Œçš®çš®é²ï¼å¾ˆé«˜å…´è®¤è¯†ä½ ã€‚æˆ‘æ˜¯ä¸€ä¸ªAIåŠ©æ‰‹ï¼Œå¯ä»¥å›ç­”ä½ çš„é—®é¢˜å’Œæä¾›å¸®åŠ©ã€‚æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®ä½ çš„å—ï¼Ÿ
    Human: 1+1ç­‰äºå¤šå°‘ï¼Ÿ
    AI:[0m
    
    [1m> Finished chain.[0m





    '1+1ç­‰äº2ã€‚'



### 1.4 ç¬¬ä¸‰è½®å¯¹è¯

ä¸ºäº†éªŒè¯ä»–æ˜¯å¦è®°å¿†äº†å‰é¢çš„å¯¹è¯å†…å®¹ï¼Œæˆ‘ä»¬è®©ä»–å›ç­”å‰é¢å·²ç»è¯´è¿‡çš„å†…å®¹ï¼ˆæˆ‘çš„åå­—ï¼‰ï¼Œå¯ä»¥çœ‹åˆ°ä»–ç¡®å®è¾“å‡ºäº†æ­£ç¡®çš„åå­—ï¼Œå› æ­¤è¿™ä¸ªå¯¹è¯é“¾éšç€å¾€ä¸‹è¿›è¡Œä¼šè¶Šæ¥è¶Šé•¿ã€‚


```python
conversation.predict(input="æˆ‘å«ä»€ä¹ˆåå­—ï¼Ÿ")
```

    
    
    [1m> Entering new ConversationChain chain...[0m
    Prompt after formatting:
    [32;1m[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.
    
    Current conversation:
    Human: ä½ å¥½, æˆ‘å«çš®çš®é²
    AI: ä½ å¥½ï¼Œçš®çš®é²ï¼å¾ˆé«˜å…´è®¤è¯†ä½ ã€‚æˆ‘æ˜¯ä¸€ä¸ªAIåŠ©æ‰‹ï¼Œå¯ä»¥å›ç­”ä½ çš„é—®é¢˜å’Œæä¾›å¸®åŠ©ã€‚æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®ä½ çš„å—ï¼Ÿ
    Human: 1+1ç­‰äºå¤šå°‘ï¼Ÿ
    AI: 1+1ç­‰äº2ã€‚
    Human: æˆ‘å«ä»€ä¹ˆåå­—ï¼Ÿ
    AI:[0m
    
    [1m> Finished chain.[0m





    'ä½ å«çš®çš®é²ã€‚'



### 1.5 æŸ¥çœ‹å‚¨å­˜ç¼“å­˜

å‚¨å­˜ç¼“å­˜(buffer)ï¼Œå³å‚¨å­˜äº†å½“å‰ä¸ºæ­¢æ‰€æœ‰çš„å¯¹è¯ä¿¡æ¯


```python
print(memory.buffer) 
```

    Human: ä½ å¥½, æˆ‘å«çš®çš®é²
    AI: ä½ å¥½ï¼Œçš®çš®é²ï¼å¾ˆé«˜å…´è®¤è¯†ä½ ã€‚æˆ‘æ˜¯ä¸€ä¸ªAIåŠ©æ‰‹ï¼Œå¯ä»¥å›ç­”ä½ çš„é—®é¢˜å’Œæä¾›å¸®åŠ©ã€‚æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®ä½ çš„å—ï¼Ÿ
    Human: 1+1ç­‰äºå¤šå°‘ï¼Ÿ
    AI: 1+1ç­‰äº2ã€‚
    Human: æˆ‘å«ä»€ä¹ˆåå­—ï¼Ÿ
    AI: ä½ å«çš®çš®é²ã€‚


ä¹Ÿå¯ä»¥é€šè¿‡`load_memory_variables({})`æ‰“å°ç¼“å­˜ä¸­çš„å†å²æ¶ˆæ¯ã€‚è¿™é‡Œçš„`{}`æ˜¯ä¸€ä¸ªç©ºå­—å…¸ï¼Œæœ‰ä¸€äº›æ›´é«˜çº§çš„åŠŸèƒ½ï¼Œä½¿ç”¨æˆ·å¯ä»¥ä½¿ç”¨æ›´å¤æ‚çš„è¾“å…¥ï¼Œå…·ä½“å¯ä»¥é€šè¿‡ LangChain çš„å®˜æ–¹æ–‡æ¡£æŸ¥è¯¢æ›´é«˜çº§çš„ç”¨æ³•ã€‚


```python
print(memory.load_memory_variables({}))
```

    {'history': 'Human: ä½ å¥½, æˆ‘å«çš®çš®é²\nAI: ä½ å¥½ï¼Œçš®çš®é²ï¼å¾ˆé«˜å…´è®¤è¯†ä½ ã€‚æˆ‘æ˜¯ä¸€ä¸ªAIåŠ©æ‰‹ï¼Œå¯ä»¥å›ç­”ä½ çš„é—®é¢˜å’Œæä¾›å¸®åŠ©ã€‚æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®ä½ çš„å—ï¼Ÿ\nHuman: 1+1ç­‰äºå¤šå°‘ï¼Ÿ\nAI: 1+1ç­‰äº2ã€‚\nHuman: æˆ‘å«ä»€ä¹ˆåå­—ï¼Ÿ\nAI: ä½ å«çš®çš®é²ã€‚'}


### 1.6 ç›´æ¥æ·»åŠ å†…å®¹åˆ°å‚¨å­˜ç¼“å­˜

æˆ‘ä»¬å¯ä»¥ä½¿ç”¨`save_context`æ¥ç›´æ¥æ·»åŠ å†…å®¹åˆ°`buffer`ä¸­ã€‚


```python
memory = ConversationBufferMemory()
memory.save_context({"input": "ä½ å¥½ï¼Œæˆ‘å«çš®çš®é²"}, {"output": "ä½ å¥½å•Šï¼Œæˆ‘å«é²è¥¿è¥¿"})
memory.load_memory_variables({})
```




    {'history': 'Human: ä½ å¥½ï¼Œæˆ‘å«çš®çš®é²\nAI: ä½ å¥½å•Šï¼Œæˆ‘å«é²è¥¿è¥¿'}



ç»§ç»­æ·»åŠ æ–°çš„å†…å®¹


```python
memory.save_context({"input": "å¾ˆé«˜å…´å’Œä½ æˆä¸ºæœ‹å‹ï¼"}, {"output": "æ˜¯çš„ï¼Œè®©æˆ‘ä»¬ä¸€èµ·å»å†’é™©å§ï¼"})
memory.load_memory_variables({})
```




    {'history': 'Human: ä½ å¥½ï¼Œæˆ‘å«çš®çš®é²\nAI: ä½ å¥½å•Šï¼Œæˆ‘å«é²è¥¿è¥¿\nHuman: å¾ˆé«˜å…´å’Œä½ æˆä¸ºæœ‹å‹ï¼\nAI: æ˜¯çš„ï¼Œè®©æˆ‘ä»¬ä¸€èµ·å»å†’é™©å§ï¼'}



å¯ä»¥çœ‹åˆ°å¯¹è¯å†å²éƒ½ä¿å­˜ä¸‹æ¥äº†ï¼

å½“æˆ‘ä»¬åœ¨ä½¿ç”¨å¤§å‹è¯­è¨€æ¨¡å‹è¿›è¡ŒèŠå¤©å¯¹è¯æ—¶ï¼Œ**å¤§å‹è¯­è¨€æ¨¡å‹æœ¬èº«å®é™…ä¸Šæ˜¯æ— çŠ¶æ€çš„ã€‚è¯­è¨€æ¨¡å‹æœ¬èº«å¹¶ä¸è®°å¾—åˆ°ç›®å‰ä¸ºæ­¢çš„å†å²å¯¹è¯**ã€‚æ¯æ¬¡è°ƒç”¨APIç»“ç‚¹éƒ½æ˜¯ç‹¬ç«‹çš„ã€‚å‚¨å­˜(Memory)å¯ä»¥å‚¨å­˜åˆ°ç›®å‰ä¸ºæ­¢çš„æ‰€æœ‰æœ¯è¯­æˆ–å¯¹è¯ï¼Œå¹¶å°†å…¶è¾“å…¥æˆ–é™„åŠ ä¸Šä¸‹æ–‡åˆ°LLMä¸­ç”¨äºç”Ÿæˆè¾“å‡ºã€‚å¦‚æ­¤çœ‹èµ·æ¥å°±å¥½åƒå®ƒåœ¨è¿›è¡Œä¸‹ä¸€è½®å¯¹è¯çš„æ—¶å€™ï¼Œè®°å¾—ä¹‹å‰è¯´è¿‡ä»€ä¹ˆã€‚


## äºŒã€å¯¹è¯ç¼“å­˜çª—å£å‚¨å­˜
  
éšç€å¯¹è¯å˜å¾—è¶Šæ¥è¶Šé•¿ï¼Œæ‰€éœ€çš„å†…å­˜é‡ä¹Ÿå˜å¾—éå¸¸é•¿ã€‚å°†å¤§é‡çš„tokenså‘é€åˆ°LLMçš„æˆæœ¬ï¼Œä¹Ÿä¼šå˜å¾—æ›´åŠ æ˜‚è´µï¼Œè¿™ä¹Ÿå°±æ˜¯ä¸ºä»€ä¹ˆAPIçš„è°ƒç”¨è´¹ç”¨ï¼Œé€šå¸¸æ˜¯åŸºäºå®ƒéœ€è¦å¤„ç†çš„tokensæ•°é‡è€Œæ”¶è´¹çš„ã€‚
  
é’ˆå¯¹ä»¥ä¸Šé—®é¢˜ï¼ŒLangChainä¹Ÿæä¾›äº†å‡ ç§æ–¹ä¾¿çš„å‚¨å­˜æ–¹å¼æ¥ä¿å­˜å†å²å¯¹è¯ã€‚å…¶ä¸­ï¼Œå¯¹è¯ç¼“å­˜çª—å£å‚¨å­˜åªä¿ç•™ä¸€ä¸ªçª—å£å¤§å°çš„å¯¹è¯ã€‚å®ƒåªä½¿ç”¨æœ€è¿‘çš„næ¬¡äº¤äº’ã€‚è¿™å¯ä»¥ç”¨äºä¿æŒæœ€è¿‘äº¤äº’çš„æ»‘åŠ¨çª—å£ï¼Œä»¥ä¾¿ç¼“å†²åŒºä¸ä¼šè¿‡å¤§ã€‚

### 2.1 æ·»åŠ ä¸¤è½®å¯¹è¯åˆ°çª—å£å‚¨å­˜

æˆ‘ä»¬å…ˆæ¥å°è¯•ä¸€ä¸‹ä½¿ç”¨`ConversationBufferWindowMemory`æ¥å®ç°äº¤äº’çš„æ»‘åŠ¨çª—å£ï¼Œå¹¶è®¾ç½®`k=1`ï¼Œè¡¨ç¤ºåªä¿ç•™ä¸€ä¸ªå¯¹è¯è®°å¿†ã€‚æ¥ä¸‹æ¥æˆ‘ä»¬æ‰‹åŠ¨æ·»åŠ ä¸¤è½®å¯¹è¯åˆ°çª—å£å‚¨å­˜ä¸­ï¼Œç„¶åæŸ¥çœ‹å‚¨å­˜çš„å¯¹è¯ã€‚


```python
from langchain.memory import ConversationBufferWindowMemory

# k=1è¡¨æ˜åªä¿ç•™ä¸€ä¸ªå¯¹è¯è®°å¿†
memory = ConversationBufferWindowMemory(k=1)  
memory.save_context({"input": "ä½ å¥½ï¼Œæˆ‘å«çš®çš®é²"}, {"output": "ä½ å¥½å•Šï¼Œæˆ‘å«é²è¥¿è¥¿"})
memory.save_context({"input": "å¾ˆé«˜å…´å’Œä½ æˆä¸ºæœ‹å‹ï¼"}, {"output": "æ˜¯çš„ï¼Œè®©æˆ‘ä»¬ä¸€èµ·å»å†’é™©å§ï¼"})
memory.load_memory_variables({})
```




    {'history': 'Human: å¾ˆé«˜å…´å’Œä½ æˆä¸ºæœ‹å‹ï¼\nAI: æ˜¯çš„ï¼Œè®©æˆ‘ä»¬ä¸€èµ·å»å†’é™©å§ï¼'}



é€šè¿‡ç»“æœï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°çª—å£å‚¨å­˜ä¸­åªæœ‰æœ€åä¸€è½®çš„èŠå¤©è®°å½•ã€‚

### 2.2 åœ¨å¯¹è¯é“¾ä¸­åº”ç”¨çª—å£å‚¨å­˜

æ¥ä¸‹æ¥ï¼Œè®©æˆ‘ä»¬æ¥çœ‹çœ‹å¦‚ä½•åœ¨`ConversationChain`ä¸­è¿ç”¨`ConversationBufferWindowMemory`å§ï¼


```python
llm = ChatOpenAI(temperature=0.0)
memory = ConversationBufferWindowMemory(k=1)
conversation = ConversationChain(llm=llm, memory=memory, verbose=False  )

print("ç¬¬ä¸€è½®å¯¹è¯ï¼š")
print(conversation.predict(input="ä½ å¥½, æˆ‘å«çš®çš®é²"))

print("ç¬¬äºŒè½®å¯¹è¯ï¼š")
print(conversation.predict(input="1+1ç­‰äºå¤šå°‘ï¼Ÿ"))

print("ç¬¬ä¸‰è½®å¯¹è¯ï¼š")
print(conversation.predict(input="æˆ‘å«ä»€ä¹ˆåå­—ï¼Ÿ"))
```

    ç¬¬ä¸€è½®å¯¹è¯ï¼š
    ä½ å¥½ï¼Œçš®çš®é²ï¼å¾ˆé«˜å…´è®¤è¯†ä½ ã€‚æˆ‘æ˜¯ä¸€ä¸ªAIåŠ©æ‰‹ï¼Œå¯ä»¥å›ç­”ä½ çš„é—®é¢˜å’Œæä¾›å¸®åŠ©ã€‚æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®ä½ çš„å—ï¼Ÿ
    ç¬¬äºŒè½®å¯¹è¯ï¼š
    1+1ç­‰äº2ã€‚
    ç¬¬ä¸‰è½®å¯¹è¯ï¼š
    å¾ˆæŠ±æ­‰ï¼Œæˆ‘æ— æ³•çŸ¥é“æ‚¨çš„åå­—ã€‚


<br>
æ³¨æ„æ­¤å¤„ï¼ç”±äºè¿™é‡Œç”¨çš„æ˜¯ä¸€ä¸ªçª—å£çš„è®°å¿†ï¼Œå› æ­¤åªèƒ½ä¿å­˜ä¸€è½®çš„å†å²æ¶ˆæ¯ï¼Œå› æ­¤AIå¹¶ä¸èƒ½çŸ¥é“ä½ ç¬¬ä¸€è½®å¯¹è¯ä¸­æåˆ°çš„åå­—ï¼Œä»–æœ€å¤šåªèƒ½è®°ä½ä¸Šä¸€è½®ï¼ˆç¬¬äºŒè½®ï¼‰çš„å¯¹è¯ä¿¡æ¯

## ä¸‰ã€å¯¹è¯å­—ç¬¦ç¼“å­˜å‚¨å­˜

ä½¿ç”¨å¯¹è¯å­—ç¬¦ç¼“å­˜è®°å¿†ï¼Œå†…å­˜å°†é™åˆ¶ä¿å­˜çš„tokenæ•°é‡ã€‚å¦‚æœå­—ç¬¦æ•°é‡è¶…å‡ºæŒ‡å®šæ•°ç›®ï¼Œå®ƒä¼šåˆ‡æ‰è¿™ä¸ªå¯¹è¯çš„æ—©æœŸéƒ¨åˆ†
ä»¥ä¿ç•™ä¸æœ€è¿‘çš„äº¤æµç›¸å¯¹åº”çš„å­—ç¬¦æ•°é‡ï¼Œä½†ä¸è¶…è¿‡å­—ç¬¦é™åˆ¶ã€‚


æ·»åŠ å¯¹è¯åˆ°Tokenç¼“å­˜å‚¨å­˜,é™åˆ¶tokenæ•°é‡ï¼Œè¿›è¡Œæµ‹è¯•


```python
from langchain.llms import OpenAI
from langchain.memory import ConversationTokenBufferMemory
memory = ConversationTokenBufferMemory(llm=llm, max_token_limit=30)
memory.save_context({"input": "æœè¾ç™½å¸å½©äº‘é—´ï¼Œ"}, {"output": "åƒé‡Œæ±Ÿé™µä¸€æ—¥è¿˜ã€‚"})
memory.save_context({"input": "ä¸¤å²¸çŒ¿å£°å•¼ä¸ä½ï¼Œ"}, {"output": "è½»èˆŸå·²è¿‡ä¸‡é‡å±±ã€‚"})
memory.load_memory_variables({})
```




    {'history': 'AI: è½»èˆŸå·²è¿‡ä¸‡é‡å±±ã€‚'}



ChatGPT ä½¿ç”¨ä¸€ç§åŸºäºå­—èŠ‚å¯¹ç¼–ç ï¼ˆByte Pair Encodingï¼ŒBPEï¼‰çš„æ–¹æ³•æ¥è¿›è¡Œ tokenization ï¼ˆå°†è¾“å…¥æ–‡æœ¬æ‹†åˆ†ä¸ºtokenï¼‰ã€‚BPE æ˜¯ä¸€ç§å¸¸è§çš„  tokenization æŠ€æœ¯ï¼Œå®ƒå°†è¾“å…¥æ–‡æœ¬åˆ†å‰²æˆè¾ƒå°çš„å­è¯å•å…ƒã€‚ OpenAI åœ¨å…¶å®˜æ–¹ GitHub ä¸Šå…¬å¼€äº†ä¸€ä¸ªæœ€æ–°çš„å¼€æº Python åº“ [tiktoken](https://github.com/openai/tiktoken)(https://github.com/openai/tiktoken)ï¼Œè¿™ä¸ªåº“ä¸»è¦æ˜¯ç”¨æ¥è®¡ç®— tokens æ•°é‡çš„ã€‚ç›¸æ¯”è¾ƒ HuggingFace çš„ tokenizer ï¼Œå…¶é€Ÿåº¦æå‡äº†å¥½å‡ å€ã€‚
å…·ä½“ token è®¡ç®—æ–¹å¼,ç‰¹åˆ«æ˜¯æ±‰å­—å’Œè‹±æ–‡å•è¯çš„ token åŒºåˆ«ï¼Œå…·ä½“å¯å‚è€ƒ[çŸ¥ä¹æ–‡ç« ](https://www.zhihu.com/question/594159910)(https://www.zhihu.com/question/594159910)ã€‚

## å››ã€å¯¹è¯æ‘˜è¦ç¼“å­˜å‚¨å­˜

å¯¹è¯æ‘˜è¦ç¼“å­˜å‚¨å­˜ï¼Œ**ä½¿ç”¨ LLM å¯¹åˆ°ç›®å‰ä¸ºæ­¢å†å²å¯¹è¯è‡ªåŠ¨æ€»ç»“æ‘˜è¦**ï¼Œå¹¶å°†å…¶ä¿å­˜ä¸‹æ¥ã€‚

### 4.1 ä½¿ç”¨å¯¹è¯æ‘˜è¦ç¼“å­˜å‚¨å­˜

æˆ‘ä»¬åˆ›å»ºäº†ä¸€ä¸ªé•¿å­—ç¬¦ä¸²ï¼Œå…¶ä¸­åŒ…å«æŸäººçš„æ—¥ç¨‹å®‰æ’ã€‚


```python
from langchain.chains import ConversationChain
from langchain.chat_models import ChatOpenAI
from langchain.memory import ConversationSummaryBufferMemory

# åˆ›å»ºä¸€ä¸ªé•¿å­—ç¬¦ä¸²
schedule = "åœ¨å…«ç‚¹ä½ å’Œä½ çš„äº§å“å›¢é˜Ÿæœ‰ä¸€ä¸ªä¼šè®®ã€‚ \
ä½ éœ€è¦åšä¸€ä¸ªPPTã€‚ \
ä¸Šåˆ9ç‚¹åˆ°12ç‚¹ä½ éœ€è¦å¿™äºLangChainã€‚\
Langchainæ˜¯ä¸€ä¸ªæœ‰ç”¨çš„å·¥å…·ï¼Œå› æ­¤ä½ çš„é¡¹ç›®è¿›å±•çš„éå¸¸å¿«ã€‚\
ä¸­åˆï¼Œåœ¨æ„å¤§åˆ©é¤å…ä¸ä¸€ä½å¼€è½¦æ¥çš„é¡¾å®¢å…±è¿›åˆé¤ \
èµ°äº†ä¸€ä¸ªå¤šå°æ—¶çš„è·¯ç¨‹ä¸ä½ è§é¢ï¼Œåªä¸ºäº†è§£æœ€æ–°çš„ AIã€‚ \
ç¡®ä¿ä½ å¸¦äº†ç¬”è®°æœ¬ç”µè„‘å¯ä»¥å±•ç¤ºæœ€æ–°çš„ LLM æ ·ä¾‹."

llm = ChatOpenAI(temperature=0.0)
memory = ConversationSummaryBufferMemory(llm=llm, max_token_limit=100)
memory.save_context({"input": "ä½ å¥½ï¼Œæˆ‘å«çš®çš®é²"}, {"output": "ä½ å¥½å•Šï¼Œæˆ‘å«é²è¥¿è¥¿"})
memory.save_context({"input": "å¾ˆé«˜å…´å’Œä½ æˆä¸ºæœ‹å‹ï¼"}, {"output": "æ˜¯çš„ï¼Œè®©æˆ‘ä»¬ä¸€èµ·å»å†’é™©å§ï¼"})
memory.save_context({"input": "ä»Šå¤©çš„æ—¥ç¨‹å®‰æ’æ˜¯ä»€ä¹ˆï¼Ÿ"}, {"output": f"{schedule}"})

print(memory.load_memory_variables({})['history'])
```

    System: The human introduces themselves as Pipilu and the AI introduces themselves as Luxixi. They express happiness at becoming friends and decide to go on an adventure together. The human asks about the schedule for the day. The AI informs them that they have a meeting with their product team at 8 o'clock and need to prepare a PowerPoint presentation. From 9 am to 12 pm, they will be busy with LangChain, a useful tool that helps their project progress quickly. At noon, they will have lunch with a customer who has driven for over an hour just to learn about the latest AI. The AI advises the human to bring their laptop to showcase the latest LLM samples.


### 4.2 åŸºäºå¯¹è¯æ‘˜è¦ç¼“å­˜å‚¨å­˜çš„å¯¹è¯é“¾

åŸºäºä¸Šé¢çš„å¯¹è¯æ‘˜è¦ç¼“å­˜å‚¨å­˜ï¼Œæˆ‘ä»¬æ–°å»ºä¸€ä¸ªå¯¹è¯é“¾ã€‚


```python
conversation = ConversationChain(llm=llm, memory=memory, verbose=True)
conversation.predict(input="å±•ç¤ºä»€ä¹ˆæ ·çš„æ ·ä¾‹æœ€å¥½å‘¢ï¼Ÿ")
```

    
    
    [1m> Entering new ConversationChain chain...[0m
    Prompt after formatting:
    [32;1m[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.
    
    Current conversation:
    System: The human introduces themselves as Pipilu and the AI introduces themselves as Luxixi. They express happiness at becoming friends and decide to go on an adventure together. The human asks about the schedule for the day. The AI informs them that they have a meeting with their product team at 8 o'clock and need to prepare a PowerPoint presentation. From 9 am to 12 pm, they will be busy with LangChain, a useful tool that helps their project progress quickly. At noon, they will have lunch with a customer who has driven for over an hour just to learn about the latest AI. The AI advises the human to bring their laptop to showcase the latest LLM samples.
    Human: å±•ç¤ºä»€ä¹ˆæ ·çš„æ ·ä¾‹æœ€å¥½å‘¢ï¼Ÿ
    AI:[0m
    
    [1m> Finished chain.[0m





    'å±•ç¤ºä¸€äº›å…·æœ‰å¤šæ ·æ€§å’Œåˆ›æ–°æ€§çš„æ ·ä¾‹å¯èƒ½æ˜¯æœ€å¥½çš„é€‰æ‹©ã€‚ä½ å¯ä»¥å±•ç¤ºä¸€äº›ä¸åŒé¢†åŸŸçš„åº”ç”¨ï¼Œæ¯”å¦‚è‡ªç„¶è¯­è¨€å¤„ç†ã€å›¾åƒè¯†åˆ«ã€è¯­éŸ³åˆæˆç­‰ã€‚å¦å¤–ï¼Œä½ ä¹Ÿå¯ä»¥å±•ç¤ºä¸€äº›å…·æœ‰å®é™…åº”ç”¨ä»·å€¼çš„æ ·ä¾‹ï¼Œæ¯”å¦‚æ™ºèƒ½å®¢æœã€æ™ºèƒ½æ¨èç­‰ã€‚æ€»ä¹‹ï¼Œé€‰æ‹©é‚£äº›èƒ½å¤Ÿå±•ç¤ºå‡ºæˆ‘ä»¬AIæŠ€æœ¯çš„å¼ºå¤§å’Œå¤šæ ·æ€§çš„æ ·ä¾‹ä¼šç»™å®¢æˆ·ç•™ä¸‹æ·±åˆ»çš„å°è±¡ã€‚'




```python
print(memory.load_memory_variables({}))  # æ‘˜è¦è®°å½•æ›´æ–°äº†
```

    {'history': "System: The human introduces themselves as Pipilu and the AI introduces themselves as Luxixi. They express happiness at becoming friends and decide to go on an adventure together. The human asks about the schedule for the day. The AI informs them that they have a meeting with their product team at 8 o'clock and need to prepare a PowerPoint presentation. From 9 am to 12 pm, they will be busy with LangChain, a useful tool that helps their project progress quickly. At noon, they will have lunch with a customer who has driven for over an hour just to learn about the latest AI. The AI advises the human to bring their laptop to showcase the latest LLM samples. The human asks what kind of samples would be best to showcase. The AI suggests that showcasing diverse and innovative samples would be the best choice. They recommend demonstrating applications in different fields such as natural language processing, image recognition, and speech synthesis. Additionally, they suggest showcasing practical examples like intelligent customer service and personalized recommendations to impress the customer with the power and versatility of their AI technology."}


é€šè¿‡å¯¹æ¯”ä¸Šä¸€æ¬¡è¾“å‡ºï¼Œå‘ç°æ‘˜è¦è®°å½•æ›´æ–°äº†ï¼Œæ·»åŠ äº†æœ€æ–°ä¸€æ¬¡å¯¹è¯çš„å†…å®¹æ€»ç»“ã€‚

## è‹±æ–‡ç‰ˆæç¤º

**1.å¯¹è¯ç¼“å­˜å‚¨å­˜**


```python
from langchain.chains import ConversationChain
from langchain.chat_models import ChatOpenAI
from langchain.memory import ConversationBufferMemory


llm = ChatOpenAI(temperature=0.0)  
memory = ConversationBufferMemory()
conversation = ConversationChain(llm=llm, memory = memory, verbose=True )

print("ç¬¬ä¸€è½®å¯¹è¯ï¼š")
conversation.predict(input="Hi, my name is Andrew")

print("ç¬¬äºŒè½®å¯¹è¯ï¼š")
conversation.predict(input="What is 1+1?")

print("ç¬¬ä¸‰è½®å¯¹è¯ï¼š")
conversation.predict(input="What is my name?")
```

    ç¬¬ä¸€è½®å¯¹è¯ï¼š
    
    
    [1m> Entering new  chain...[0m
    Prompt after formatting:
    [32;1m[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.
    
    Current conversation:
    
    Human: Hi, my name is Andrew
    AI:[0m
    
    [1m> Finished chain.[0m
    ç¬¬äºŒè½®å¯¹è¯ï¼š
    
    
    [1m> Entering new  chain...[0m
    Prompt after formatting:
    [32;1m[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.
    
    Current conversation:
    Human: Hi, my name is Andrew
    AI: Hello Andrew! It's nice to meet you. How can I assist you today?
    Human: What is 1+1?
    AI:[0m
    
    [1m> Finished chain.[0m
    ç¬¬ä¸‰è½®å¯¹è¯ï¼š
    
    
    [1m> Entering new  chain...[0m
    Prompt after formatting:
    [32;1m[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.
    
    Current conversation:
    Human: Hi, my name is Andrew
    AI: Hello Andrew! It's nice to meet you. How can I assist you today?
    Human: What is 1+1?
    AI: 1+1 is equal to 2.
    Human: What is my name?
    AI:[0m
    
    [1m> Finished chain.[0m





    'Your name is Andrew.'




```python
print("æŸ¥çœ‹å‚¨å­˜ç¼“å­˜æ–¹å¼ä¸€ï¼š")
print(memory.buffer) 

print("æŸ¥çœ‹å‚¨å­˜ç¼“å­˜æ–¹å¼äºŒï¼š")
print(memory.load_memory_variables({}))

print("å‘ç¼“å­˜åŒºæ·»åŠ æŒ‡å®šå¯¹è¯çš„è¾“å…¥è¾“å‡º, å¹¶æŸ¥çœ‹")
memory = ConversationBufferMemory()  # æ–°å»ºä¸€ä¸ªç©ºçš„å¯¹è¯ç¼“å­˜è®°å¿†
memory.save_context({"input": "Hi"}, {"output": "What's up"})  # å‘ç¼“å­˜åŒºæ·»åŠ æŒ‡å®šå¯¹è¯çš„è¾“å…¥è¾“å‡º
print(memory.buffer)  # æŸ¥çœ‹ç¼“å­˜åŒºç»“æœ
print(memory.load_memory_variables({}))# å†æ¬¡åŠ è½½è®°å¿†å˜é‡

print("ç»§ç»­å‘å‘ç¼“å­˜åŒºæ·»åŠ æŒ‡å®šå¯¹è¯çš„è¾“å…¥è¾“å‡º, å¹¶æŸ¥çœ‹")
memory.save_context({"input": "Not much, just hanging"}, {"output": "Cool"})
print(memory.buffer)  # æŸ¥çœ‹ç¼“å­˜åŒºç»“æœ
print(memory.load_memory_variables({}))# å†æ¬¡åŠ è½½è®°å¿†å˜é‡

```

    æŸ¥çœ‹å‚¨å­˜ç¼“å­˜æ–¹å¼ä¸€ï¼š
    Human: Hi, my name is Andrew
    AI: Hello Andrew! It's nice to meet you. How can I assist you today?
    Human: What is 1+1?
    AI: 1+1 is equal to 2.
    Human: What is my name?
    AI: Your name is Andrew.
    æŸ¥çœ‹å‚¨å­˜ç¼“å­˜æ–¹å¼äºŒï¼š
    {'history': "Human: Hi, my name is Andrew\nAI: Hello Andrew! It's nice to meet you. How can I assist you today?\nHuman: What is 1+1?\nAI: 1+1 is equal to 2.\nHuman: What is my name?\nAI: Your name is Andrew."}
    å‘ç¼“å­˜åŒºæ·»åŠ æŒ‡å®šå¯¹è¯çš„è¾“å…¥è¾“å‡º, å¹¶æŸ¥çœ‹
    Human: Hi
    AI: What's up
    {'history': "Human: Hi\nAI: What's up"}
    ç»§ç»­å‘å‘ç¼“å­˜åŒºæ·»åŠ æŒ‡å®šå¯¹è¯çš„è¾“å…¥è¾“å‡º, å¹¶æŸ¥çœ‹
    Human: Hi
    AI: What's up
    Human: Not much, just hanging
    AI: Cool
    {'history': "Human: Hi\nAI: What's up\nHuman: Not much, just hanging\nAI: Cool"}


**2. å¯¹è¯ç¼“å­˜çª—å£å‚¨å­˜**


```python
from langchain.memory import ConversationBufferWindowMemory

# k ä¸ºçª—å£å‚æ•°ï¼Œk=1è¡¨æ˜åªä¿ç•™ä¸€ä¸ªå¯¹è¯è®°å¿†
memory = ConversationBufferWindowMemory(k=1)  

# å‘memoryæ·»åŠ ä¸¤è½®å¯¹è¯
memory.save_context({"input": "Hi"}, {"output": "What's up"})
memory.save_context({"input": "Not much, just hanging"}, {"output": "Cool"})

# å¹¶æŸ¥çœ‹è®°å¿†å˜é‡å½“å‰çš„è®°å½•
memory.load_memory_variables({})


llm = ChatOpenAI(temperature=0.0)
memory = ConversationBufferWindowMemory(k=1)
conversation = ConversationChain(llm=llm, memory=memory, verbose=False  )


print("ç¬¬ä¸€è½®å¯¹è¯ï¼š")
print(conversation.predict(input="Hi, my name is Andrew"))

print("ç¬¬äºŒè½®å¯¹è¯ï¼š")
print(conversation.predict(input="What is 1+1?"))

print("ç¬¬ä¸‰è½®å¯¹è¯ï¼š")
print(conversation.predict(input="What is my name?"))
```

    ç¬¬ä¸€è½®å¯¹è¯ï¼š
    Hello Andrew! It's nice to meet you. How can I assist you today?
    ç¬¬äºŒè½®å¯¹è¯ï¼š
    1+1 is equal to 2.
    ç¬¬ä¸‰è½®å¯¹è¯ï¼š
    I'm sorry, but I don't have access to personal information.


**3. å¯¹è¯å­—ç¬¦ç¼“å­˜å‚¨å­˜**


```python
from langchain.llms import OpenAI
from langchain.memory import ConversationTokenBufferMemory
memory = ConversationTokenBufferMemory(llm=llm, max_token_limit=30)
memory.save_context({"input": "AI is what?!"}, {"output": "Amazing!"})
memory.save_context({"input": "Backpropagation is what?"}, {"output": "Beautiful!"})
memory.save_context({"input": "Chatbots are what?"}, {"output": "Charming!"})
print(memory.load_memory_variables({}))
```

    {'history': 'AI: Beautiful!\nHuman: Chatbots are what?\nAI: Charming!'}


**4. å¯¹è¯æ‘˜è¦ç¼“å­˜å‚¨å­˜**


```python
from langchain.chains import ConversationChain
from langchain.chat_models import ChatOpenAI
from langchain.memory import ConversationSummaryBufferMemory

# åˆ›å»ºä¸€ä¸ªé•¿å­—ç¬¦ä¸²
schedule = "There is a meeting at 8am with your product team. \
You will need your powerpoint presentation prepared. \
9am-12pm have time to work on your LangChain \
project which will go quickly because Langchain is such a powerful tool. \
At Noon, lunch at the italian resturant with a customer who is driving \
from over an hour away to meet you to understand the latest in AI. \
Be sure to bring your laptop to show the latest LLM demo."

# ä½¿ç”¨å¯¹è¯æ‘˜è¦ç¼“å­˜
llm = ChatOpenAI(temperature=0.0)
memory = ConversationSummaryBufferMemory(llm=llm, max_token_limit=100) 
memory.save_context({"input": "Hello"}, {"output": "What's up"})
memory.save_context({"input": "Not much, just hanging"}, {"output": "Cool"})
memory.save_context({"input": "What is on the schedule today?"}, {"output": f"{schedule}"})

print("æŸ¥çœ‹å¯¹è¯æ‘˜è¦ç¼“å­˜å‚¨å­˜")
print(memory.load_memory_variables({})['history'])

conversation = ConversationChain(llm=llm, memory=memory, verbose=True)

print("åŸºäºå¯¹è¯æ‘˜è¦ç¼“å­˜å‚¨å­˜çš„å¯¹è¯é“¾")
conversation.predict(input="What would be a good demo to show?")

print("å†æ¬¡æŸ¥çœ‹å¯¹è¯æ‘˜è¦ç¼“å­˜å‚¨å­˜")
print(memory.load_memory_variables({})['history'])
```

    æŸ¥çœ‹å¯¹è¯æ‘˜è¦ç¼“å­˜å‚¨å­˜
    System: The human and AI exchange greetings. The human asks about the schedule for the day. The AI provides a detailed schedule, including a meeting with the product team, work on the LangChain project, and a lunch meeting with a customer interested in AI. The AI emphasizes the importance of bringing a laptop to showcase the latest LLM demo during the lunch meeting.
    åŸºäºå¯¹è¯æ‘˜è¦ç¼“å­˜å‚¨å­˜çš„å¯¹è¯é“¾
    
    
    [1m> Entering new  chain...[0m
    Prompt after formatting:
    [32;1m[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.
    
    Current conversation:
    System: The human and AI exchange greetings. The human asks about the schedule for the day. The AI provides a detailed schedule, including a meeting with the product team, work on the LangChain project, and a lunch meeting with a customer interested in AI. The AI emphasizes the importance of bringing a laptop to showcase the latest LLM demo during the lunch meeting.
    Human: What would be a good demo to show?
    AI:[0m
    
    [1m> Finished chain.[0m
    å†æ¬¡æŸ¥çœ‹å¯¹è¯æ‘˜è¦ç¼“å­˜å‚¨å­˜
    System: The human and AI exchange greetings and discuss the schedule for the day. The AI provides a detailed schedule, including a meeting with the product team, work on the LangChain project, and a lunch meeting with a customer interested in AI. The AI emphasizes the importance of bringing a laptop to showcase the latest LLM demo during the lunch meeting. The human asks what would be a good demo to show, and the AI suggests showcasing the latest LLM (Language Model) demo. The LLM is a cutting-edge AI model that can generate human-like text based on a given prompt. It has been trained on a vast amount of data and can generate coherent and contextually relevant responses. By showcasing the LLM demo, the AI can demonstrate the capabilities of their AI technology and how it can be applied to various industries and use cases.

